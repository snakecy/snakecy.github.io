<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Snakecy's Blog]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="https://snakecy.github.io/"/>
  <updated>2016-03-10T13:12:58.000Z</updated>
  <id>https://snakecy.github.io/</id>
  
  <author>
    <name><![CDATA[SZhou]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[ipinyou-database]]></title>
    <link href="https://snakecy.github.io/2016/03/10/ipinyou-database/"/>
    <id>https://snakecy.github.io/2016/03/10/ipinyou-database/</id>
    <published>2016-03-10T12:35:08.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<h3 id="iPinyou_Reference"><a href="#iPinyou_Reference" class="headerlink" title="iPinyou Reference"></a>iPinyou Reference</h3><blockquote>
<hr>
<p>  Ipinyou database<br>Features = {IP,Region,City,Ad exchange,ad slot id,ad slot width, ad slot height,ad visiblility,ad slot format,advertiser id,user tags}</p>
<hr>
</blockquote>
<ul>
<li><p>RankSorce = CTR * BidPrice</p>
<ul>
<li><a href="http://sobuhu.com/ml/2013/01/25/r-ctr.html" target="_blank" rel="external">Advertising Calculating</a></li>
</ul>
</li>
<li><p>Aim</p>
<ul>
<li>Low-latency and scalale predictions as a service</li>
<li>Integrated approach leads to fresher, better predictions</li>
<li>Easy translation to production predictions</li>
<li>Eases Operational pain</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h4 id="Experiment_using_R"><a href="#Experiment_using_R" class="headerlink" title="Experiment using R"></a>Experiment using R</h4><ul>
<li><p>First //</p>
<ul>
<li><a href="https://github.com/wnzhang/make-ipinyou-data" target="_blank" rel="external">make-ipinyou-data</a></li>
<li>Paper: Real-Time Bidding Benchmarking with iPinYou Dataset</li>
</ul>
</li>
<li><p>Second</p>
<ul>
<li><a href="https://github.com/wnzhang/rtbcontrol" target="_blank" rel="external">rtbcontrol</a></li>
<li>Paper: Experiment Code for RTB Feedback Control Techniques</li>
</ul>
</li>
<li><p>Third</p>
<ul>
<li><a href="https://github.com/wnzhang/rtbarbitrage" target="_blank" rel="external">rtbarbitrage</a></li>
<li>Paper: Statistical Arbitrage Mining for Display Advertising</li>
</ul>
</li>
<li><p>Fourth //</p>
<ul>
<li><a href="https://github.com/wnzhang/optimal-rtb" target="_blank" rel="external">optimal-rtb</a></li>
<li>Paper: Optimal Real-Time Bidding for Display Advertising</li>
</ul>
</li>
<li><p>Fifth</p>
<ul>
<li><a href="https://github.com/wush978/KDD2015wpp" target="_blank" rel="external">KDD2015wpp</a></li>
<li>Predicting Winning Price in Real Time Bidding with Censored Data</li>
</ul>
</li>
</ul>
<h3 id="Winning_price_steps"><a href="#Winning_price_steps" class="headerlink" title="Winning price steps"></a>Winning price steps</h3><ul>
<li>What features should be taken in</li>
<li>Considering of the Winning Rate</li>
<li>Combine Win Rate &amp; Winning Price<ul>
<li><a href="http://blog.csdn.net/star_liux/article/details/39666737" target="_blank" rel="external">logistic factor solution</a></li>
<li>Paper reference<ul>
<li><a href="http://www.slideshare.net/WushWu/predicting-winning-price-in-real-time-bidding-with-censored-data" target="_blank" rel="external">http://www.slideshare.net/WushWu/predicting-winning-price-in-real-time-bidding-with-censored-data</a></li>
<li>Programmatic buying bidding strategies with Win Rate and Winning Price Estimation in real time mobile advertising</li>
</ul>
</li>
</ul>
</li>
<li>Join bid_req, bid_resp and win_notice for Winning Rate/Winning Price Prediction</li>
</ul>
<ul>
<li>Testing Winning Rate running by python (examples with ipinyou)<ul>
<li>Example of CTR Using Python<ul>
<li><a href="http://www.dataguru.cn/thread-460417-1-1.html" target="_blank" rel="external">http://www.dataguru.cn/thread-460417-1-1.html</a>  </li>
</ul>
</li>
<li>Example of CTR using R<ul>
<li><a href="http://f.dataguru.cn/thread-329637-1-1.html" target="_blank" rel="external">http://f.dataguru.cn/thread-329637-1-1.html</a>  </li>
<li><a href="http://blog.csdn.net/yucan1001/article/details/23228053" target="_blank" rel="external">http://blog.csdn.net/yucan1001/article/details/23228053</a>  </li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#CRT_DATA.txt</span></span><br><span class="line">0 20 0.294181968932 0.508158622733 0.182334278695 0.629420618229</span><br><span class="line">0 68 0.1867187241 0.606174671096 0.0748709302071 0.806387550943</span><br><span class="line">0 18 0.62087371082 0.497772456954 0.0321750684638 0.629224616618</span><br><span class="line">1 90 0.521405561387 0.476048142961 0.134707792901 0.400062294097</span><br><span class="line">0 75 0.0126899618353 0.507688693623 0.377923880332 0.998697036848</span><br><span class="line">0 8 0.308646073229 0.930652495254 0.755735916926 0.0519441699996</span><br><span class="line">0 64 0.444668888126 0.768001428418 0.501163712702 0.418327345087</span><br><span class="line">0 79 0.842532595853 0.817052919537 0.0709486928253 0.552712019723</span><br><span class="line">1 32 0.410650495262 0.164977576847 0.491438436479 0.886456782492</span><br><span class="line">// first col is whether click, second is the number of impressions</span><br><span class="line"></span><br><span class="line">ctr_data &lt;- read.csv(<span class="string">'CTR_DATA.txt'</span>,header = F, sep = <span class="string">" "</span>)</span><br><span class="line">head(ctr_data)</span><br><span class="line">attach(ctr_data)</span><br><span class="line">ctr_logr &lt;- glm(cbind(V1,V2)~V3+V4+V5+V6,family=binomial(link=<span class="string">"logit"</span>))</span><br><span class="line">record &lt;- data.frame(V3=0.294181968932,V4=0.508158622733,V5=0.182334278695,V6=0.629420618229)</span><br><span class="line">d &lt;- predict(ctr_logr,newdata = record,<span class="built_in">type</span>=<span class="string">"response"</span>)</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="iPinyou_Reference"><a href="#iPinyou_Reference" class="headerlink" title="iPinyou Reference"></a>iPinyou Reference</h3><blockquote>
<hr>
<p>  Ipinyou database<br>Features = {IP,Region,City,Ad exchange,ad slot id,ad slot width, ad slot height,ad visiblility,ad slot format,advertiser id,user tags}</p>
<hr>
</blockquote>
<ul>
<li><p>RankSorce = CTR * BidPrice</p>
<ul>
<li><a href="http://sobuhu.com/ml/2013/01/25/r-ctr.html">Advertising Calculating</a></li>
</ul>
</li>
<li><p>Aim</p>
<ul>
<li>Low-latency and scalale predictions as a service</li>
<li>Integrated approach leads to fresher, better predictions</li>
<li>Easy translation to production predictions</li>
<li>Eases Operational pain</li>
</ul>
</li>
</ul>]]>
    
    </summary>
    
      <category term="R" scheme="https://snakecy.github.io/tags/R/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[machine-learning-scala]]></title>
    <link href="https://snakecy.github.io/2016/03/10/machine-learning-scala/"/>
    <id>https://snakecy.github.io/2016/03/10/machine-learning-scala/</id>
    <published>2016-03-09T16:26:44.000Z</published>
    <updated>2016-03-12T06:48:47.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<hr>
<p>Good Example: REST API &amp; Velox<br><a href="http://www.slideshare.net/dscrankshaw/veloxampcamp5-final" target="_blank" rel="external">PPT</a><br><a href="http://arxiv.org/pdf/1409.3809v2.pdf" target="_blank" rel="external">Papre</a><br><a href="https://github.com/amplab/velox-modelserver" target="_blank" rel="external">Github</a></p>
<hr>
</blockquote>
<h3 id="Construct_project_2C_with_SBT__26amp_3B_dependencies"><a href="#Construct_project_2C_with_SBT__26amp_3B_dependencies" class="headerlink" title="Construct project, with SBT &amp; dependencies"></a>Construct project, with SBT &amp; dependencies</h3><blockquote>
<p>The reference example project can be found on <a href="https://snakecy.github.io">my github</a></p>
</blockquote>
<a id="more"></a>
<ul>
<li><p>think-bayes</p>
<ul>
<li>github <a href="https://github.com/ruippeixotog/think-bayes-scala" target="_blank" rel="external">https://github.com/ruippeixotog/think-bayes-scala</a></li>
<li>Repository  <a href="https://maven-repository.com/artifact/net.ruippeixotog/think-bayes_2.11/0.1" target="_blank" rel="external">https://maven-repository.com/artifact/net.ruippeixotog/think-bayes_2.11/0.1</a></li>
<li>probability density function of the standard normal distribution &amp; cumulative density function of the standard normal distribution</li>
<li>libraryDependencies += “net.ruippeixotog” % “think-bayes_2.11” % “0.1”</li>
</ul>
</li>
<li><p>Other libraryDependencies</p>
<ul>
<li>spark-core_2.10</li>
<li>spark-mllib_2.10</li>
<li>jblas</li>
</ul>
</li>
<li><p>Using IntelliJ IDEA to package scala with spark</p>
<ul>
<li>The reason of the Scala for Eclipse is not comfortable in using</li>
<li>Support code checking, cvs/ant/maven/git</li>
<li>JDK, Scala</li>
</ul>
</li>
<li><p>Censored regression model, contains 5 scala class</p>
<ul>
<li>Main class -&gt; TestTrainer.scala</li>
<li>optimization.scala</li>
<li>gradient.scala</li>
<li>linalg.scala</li>
<li>utils.scala</li>
<li>build.sbt</li>
</ul>
</li>
</ul>
<h4 id="Complie"><a href="#Complie" class="headerlink" title="Complie"></a>Complie</h4><ul>
<li>Ref to: spark-shell –packages com.databricks:spark-csv_2.11:1.2.0</li>
<li>spark-shell –packages net.ruippeixotog:think-bayes_2.11:0.1</li>
<li>Using the think-bayes to check the Pdf() and Cdf() functions<ul>
<li>SBT package for think-bayes with scala 2.10.4</li>
<li>./bin/spark-shell –driver-class-path /home/azureuser/think-bayes-scala/target/scala-2.10/think-bayes_2.10-1.0-SNAPSHOT.jar</li>
<li>then, import thinkbayes._</li>
</ul>
</li>
</ul>
<h4 id="sbt_assembly_methods"><a href="#sbt_assembly_methods" class="headerlink" title="sbt assembly methods"></a>sbt assembly methods</h4><ul>
<li><p>Scala library<br><a href="http://www.scala-lang.org/api/current/index.html#scala.math.package" target="_blank" rel="external">http://www.scala-lang.org/api/current/index.html#scala.math.package</a></p>
</li>
<li><p>Creat a project/assembly.sbt</p>
<ul>
<li>Add<br>-addSbtPlugin(“com.eed3si9n” % “sbt-assembly” % “0.14.1”)</li>
<li>When using sbt 0.13.5<ul>
<li>addSbtPlugin(“com.eed3si9n” % “sbt-assembly” % “0.11.2”)</li>
</ul>
</li>
</ul>
</li>
<li><p>Add in build.sbt</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mergeStrategy <span class="keyword">in</span> assembly := &#123;</span><br><span class="line">  <span class="keyword">case</span> m <span class="keyword">if</span> m.toLowerCase.endsWith(<span class="string">"manifest.mf"</span>)          =&gt; MergeStrategy.discard</span><br><span class="line">  <span class="keyword">case</span> m <span class="keyword">if</span> m.toLowerCase.matches(<span class="string">"meta-inf.*\\.sf$"</span>)      =&gt; MergeStrategy.discard</span><br><span class="line">  <span class="keyword">case</span> <span class="string">"log4j.properties"</span>                                  =&gt; MergeStrategy.discard</span><br><span class="line">  <span class="keyword">case</span> m <span class="keyword">if</span> m.toLowerCase.startsWith(<span class="string">"meta-inf/services/"</span>) =&gt; MergeStrategy.filterDistinctLines</span><br><span class="line">  <span class="keyword">case</span> <span class="string">"reference.conf"</span>                                    =&gt; MergeStrategy.concat</span><br><span class="line">  <span class="keyword">case</span> _                                                   =&gt; MergeStrategy.first</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Dependencies</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">libraryDependencies ++= Seq(</span><br><span class="line">  <span class="string">"com.github.wookietreiber"</span> %% <span class="string">"scala-chart"</span>   % <span class="string">"0.5.0"</span>,</span><br><span class="line">  <span class="string">"nz.ac.waikato.cms.weka"</span>    % <span class="string">"weka-stable"</span>   % <span class="string">"3.6.13"</span>,  </span><br><span class="line"> <span class="string">"org.apache.commons"</span>        % <span class="string">"commons-math3"</span> % <span class="string">"3.5"</span>,  </span><br><span class="line"> <span class="string">"org.specs2"</span>               %% <span class="string">"specs2-core"</span>   %  <span class="string">"3.6.5"</span> % <span class="string">"test"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><a href="https://github.com/sbt/sbt-assembly" target="_blank" rel="external">https://github.com/sbt/sbt-assembly</a></li>
<li><a href="https://github.com/ruippeixotog/think-bayes-scala/blob/master/build.sbt" target="_blank" rel="external">https://github.com/ruippeixotog/think-bayes-scala/blob/master/build.sbt</a></li>
<li><p><a href="https://maven-repository.com/artifact/net.ruippeixotog/think-bayes_2.11/0.1" target="_blank" rel="external">https://maven-repository.com/artifact/net.ruippeixotog/think-bayes_2.11/0.1</a></p>
</li>
<li><p>Ref to build spark using scala 2.11</p>
<ul>
<li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-building-from-sources.html" target="_blank" rel="external">https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-building-from-sources.html</a>  </li>
</ul>
</li>
</ul>
<ul>
<li><p>Push source to Github with SourceTree</p>
<ul>
<li>new clone</li>
<li>repositry</li>
<li>commit</li>
<li>push</li>
</ul>
</li>
<li><p>Keen on study on the function of pdf and cdf in censored regression model</p>
<ul>
<li>Self-defined the function using normal distribution function<ul>
<li>f(x) -&gt; 1/(sqrt(2pi)<em>sigma) </em> exp(-(x-u)^2/2*sigma^2)</li>
<li>then f(x) accumulate to cdf</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<hr>
<p>Good Example: REST API &amp; Velox<br><a href="http://www.slideshare.net/dscrankshaw/veloxampcamp5-final">PPT</a><br><a href="http://arxiv.org/pdf/1409.3809v2.pdf">Papre</a><br><a href="https://github.com/amplab/velox-modelserver">Github</a></p>
<hr>
</blockquote>
<h3 id="Construct_project_2C_with_SBT__26amp_3B_dependencies"><a href="#Construct_project_2C_with_SBT__26amp_3B_dependencies" class="headerlink" title="Construct project, with SBT &amp; dependencies"></a>Construct project, with SBT &amp; dependencies</h3><blockquote>
<p>The reference example project can be found on <a href="https://snakecy.github.io">my github</a></p>
</blockquote>]]>
    
    </summary>
    
      <category term="Spark" scheme="https://snakecy.github.io/tags/Spark/"/>
    
      <category term="Scala" scheme="https://snakecy.github.io/tags/Scala/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[perl-example]]></title>
    <link href="https://snakecy.github.io/2016/02/11/perl-example/"/>
    <id>https://snakecy.github.io/2016/02/11/perl-example/</id>
    <published>2016-02-11T15:12:07.000Z</published>
    <updated>2016-03-11T16:22:43.000Z</updated>
    <content type="html"><![CDATA[<h3 id="install_tutorial"><a href="#install_tutorial" class="headerlink" title="install tutorial"></a>install tutorial</h3><blockquote>
<p>Perl install</p>
<p>sudo apt-get update</p>
<p>sudo apt-get upgrade</p>
<p>sudo apt-get install -y perl</p>
<p>perl -version</p>
</blockquote>
<ul>
<li>my $secstr = join(“\t\t”,@items2[1…$#items2]);</li>
</ul>
<a id="more"></a>
<ul>
<li>perl example:</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/perl -w</span></span><br><span class="line">die <span class="string">"perl <span class="variable">$0</span> perl infile1 infile2 &gt; outfile.xls\n"</span> unless @ARGV == 2;</span><br><span class="line"><span class="variable">$infile1</span> = <span class="built_in">shift</span>;</span><br><span class="line"><span class="variable">$infile2</span> = <span class="built_in">shift</span>;</span><br><span class="line"><span class="built_in">print</span> <span class="string">"ID\tP1_counts\tP2_counts\n"</span>;</span><br><span class="line">my %data;</span><br><span class="line">open IN, <span class="variable">$infile1</span> or die $!;</span><br><span class="line"><span class="keyword">while</span>(&lt;IN&gt;)&#123;</span><br><span class="line">	chomp;</span><br><span class="line">	my @items = split /\s+\/;</span><br><span class="line">	my <span class="variable">$str</span> = <span class="variable">$items</span>[1];</span><br><span class="line">	<span class="variable">$data</span>&#123;<span class="variable">$items</span>[0]&#125; = <span class="variable">$str</span>;</span><br><span class="line">&#125;</span><br><span class="line">close IN;</span><br><span class="line">my <span class="variable">$str1</span> = 0;</span><br><span class="line"><span class="comment"># print "$str1\n";</span></span><br><span class="line">open IN, <span class="variable">$infile2</span> or die $!;</span><br><span class="line"><span class="keyword">while</span>(&lt;IN&gt;)&#123;</span><br><span class="line">	chomp;</span><br><span class="line">	my @items2 = split /\s+/;</span><br><span class="line">	my <span class="variable">$str2</span> = <span class="variable">$items2</span>[1];</span><br><span class="line">	<span class="keyword">if</span>(<span class="variable">$data</span>&#123;<span class="variable">$items2</span>[0]&#125;)&#123;</span><br><span class="line">		<span class="built_in">print</span> <span class="string">"<span class="variable">$items2</span>[0]\t<span class="variable">$data</span>&#123;<span class="variable">$items2</span>[0]&#125;\t<span class="variable">$str2</span>\n"</span>;</span><br><span class="line">		delete <span class="variable">$data</span>&#123;<span class="variable">$items2</span>[0]&#125;;</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="built_in">print</span> <span class="string">"<span class="variable">$items2</span>[0]\t<span class="variable">$str1</span>\t<span class="variable">$str2</span>\n"</span>;</span><br><span class="line">		delete <span class="variable">$data</span>&#123;<span class="variable">$items2</span>[0]&#125;;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">close IN;</span><br><span class="line">foreach my <span class="variable">$chr</span> (keys %data)&#123;</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"<span class="variable">$chr</span>\t<span class="variable">$data</span>&#123;<span class="variable">$chr</span>&#125;\t<span class="variable">$str1</span>\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># output combine to files</span></span><br><span class="line"><span class="comment">#open COMBINE, "&gt; tmp.xls" or die "Unable to create combine file : $!";</span></span><br><span class="line"><span class="comment">#foreach (sort keys %data)&#123;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># COMBINE $data&#123;$itesm[0]&#125;&#123;$items[1]&#125;,"\n";</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment">#close COMBINE;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>How to split array in perl file</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">        my <span class="variable">$datetime</span> = <span class="variable">$items2</span>[5];</span><br><span class="line"><span class="comment">#       my @straing = split /[-\s:]+/, $datatime;</span></span><br><span class="line">        my @time = split(/[[:space:]]+/,<span class="variable">$datetime</span>);</span><br><span class="line">        my @day = split(/-/,<span class="variable">$time</span>[0]);</span><br><span class="line">        my @hr = split(/:/,<span class="variable">$time</span>[1]);</span><br></pre></td></tr></table></figure>
<p>Question: If there is 10g file data 10g, but there are a lot of row is duplicated and need to merge the duplicate rows with a line, there are two ways to achieve. <a href="http://www.jb51.net/article/34992.htm" target="_blank" rel="external">Ref</a></p>
<ul>
<li><p>cat data |sort|uniq &gt; new_data # cost too much time</p>
</li>
<li><p>A small tool processed by perl.</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/perl</span></span><br><span class="line">use warnings;</span><br><span class="line">use strict;</span><br><span class="line"><span class="comment"># creat a hash, each raw as a key value, then using the number of each line to fill the key value.</span></span><br><span class="line"></span><br><span class="line"> my %<span class="built_in">hash</span>;</span><br><span class="line">my <span class="variable">$script</span> = <span class="variable">$0</span>; <span class="comment"># Get the script name</span></span><br><span class="line"> sub usage</span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Usage:\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"perl <span class="variable">$script</span> &lt;source_file&gt; &lt;dest_file&gt;\n"</span>);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment"># If the number of parameters less than 2 ,exit the script</span></span><br><span class="line"><span class="keyword">if</span> ( <span class="variable">$#ARGV</span>+1 &lt; 2) &#123;</span><br><span class="line">         &amp;usage;</span><br><span class="line">        <span class="built_in">exit</span> 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">my <span class="variable">$source_file</span> = <span class="variable">$ARGV</span>[0]; <span class="comment">#File need to remove duplicate rows</span></span><br><span class="line">my <span class="variable">$dest_file</span> = <span class="variable">$ARGV</span>[1]; <span class="comment"># File after remove duplicates rows</span></span><br><span class="line"> open (FILE,<span class="string">"&lt;<span class="variable">$source_file</span>"</span>) or die <span class="string">"Cannot open file $!\n"</span>;</span><br><span class="line">open (SORTED,<span class="string">"&gt;<span class="variable">$dest_file</span>"</span>) or die <span class="string">"Cannot open file $!\n"</span>;</span><br><span class="line"> <span class="keyword">while</span>(defined (my <span class="variable">$line</span> = &lt;FILE&gt;))</span><br><span class="line">&#123;</span><br><span class="line">        chomp(<span class="variable">$line</span>);</span><br><span class="line">        <span class="variable">$hash</span>&#123;<span class="variable">$line</span>&#125; += 1;</span><br><span class="line">        <span class="comment"># print "$line,$hash&#123;$line&#125;\n";</span></span><br><span class="line">&#125;</span><br><span class="line"> foreach my <span class="variable">$k</span> (keys %<span class="built_in">hash</span>) &#123;</span><br><span class="line">        <span class="built_in">print</span> SORTED <span class="string">"<span class="variable">$k</span>,<span class="variable">$hash</span>&#123;<span class="variable">$k</span>&#125;\n"</span>; <span class="comment">#change the line and print out the col, as well as the number of col to objective file</span></span><br><span class="line">&#125;</span><br><span class="line">close (FILE);</span><br><span class="line">close (SORTED);</span><br></pre></td></tr></table></figure>
<h3 id="Regular_Expression"><a href="#Regular_Expression" class="headerlink" title="Regular Expression"></a>Regular Expression</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str=<span class="string">"this is a string"</span></span><br><span class="line"><span class="comment"># estimate if the character "this" is contained in str, using the following statement</span></span><br><span class="line"></span><br><span class="line">[[ <span class="variable">$str</span> =~ <span class="string">"this"</span> ]] &amp;&amp; <span class="built_in">echo</span> <span class="string">"\$str contains this"</span></span><br><span class="line">[[ <span class="variable">$str</span> =~ <span class="string">"that"</span> ]] || <span class="built_in">echo</span> <span class="string">"\$str does NOT contain this"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>judge symbol “[[“<br>match symbol “=~”</p>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="install_tutorial"><a href="#install_tutorial" class="headerlink" title="install tutorial"></a>install tutorial</h3><blockquote>
<p>Perl install</p>
<p>sudo apt-get update</p>
<p>sudo apt-get upgrade</p>
<p>sudo apt-get install -y perl</p>
<p>perl -version</p>
</blockquote>
<ul>
<li>my $secstr = join(“\t\t”,@items2[1…$#items2]);</li>
</ul>]]>
    
    </summary>
    
      <category term="Perl" scheme="https://snakecy.github.io/tags/Perl/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[about-libsvm]]></title>
    <link href="https://snakecy.github.io/2016/02/10/about-libsvm/"/>
    <id>https://snakecy.github.io/2016/02/10/about-libsvm/</id>
    <published>2016-02-09T17:13:22.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>About the applications using libsvm tools on different platform.</p>
<p><a href="http://jacoxu.com/?p=118" target="_blank" rel="external">libsvm tutorial</a></p>
<p>which can be used on the following platform, such as Java, matlab(64 bit), python, svm-toy.</p>
<a id="more"></a>
<p><a href="https://github.com/bwaldvogel/liblinear-java" target="_blank" rel="external">liblinear-java-1.95.jar</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training:  java -cp liblinear-java-1.95.jar de.bwaldvogel.liblinear.Train <span class="_">-s</span> 0 data_file</span><br><span class="line">prediction: java -cp liblinear-java-1.95.jar de.bwaldvogel.liblinear.Prediction -b 1 <span class="built_in">test</span>_file data_file.model output_file</span><br></pre></td></tr></table></figure>
<p><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/distributed-liblinear/spark/running_spark_liblinear.html" target="_blank" rel="external">Spark liblinear</a></p>
<ul>
<li>Limited for the JDK version (before 8u)</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>About the applications using libsvm tools on different platform.</p>
<p><a href="http://jacoxu.com/?p=118">libsvm tutorial</a></p>
<p>which can be used on the following platform, such as Java, matlab(64 bit), python, svm-toy.</p>]]>
    
    </summary>
    
      <category term="Libsvm" scheme="https://snakecy.github.io/tags/Libsvm/"/>
    
      <category term="Java" scheme="https://snakecy.github.io/tags/Java/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Resolve the debug problem of WARN NativeCodeLoader]]></title>
    <link href="https://snakecy.github.io/2016/02/10/debug-nativecodeloader/"/>
    <id>https://snakecy.github.io/2016/02/10/debug-nativecodeloader/</id>
    <published>2016-02-09T16:58:25.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<h3 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h3><p>Resolve the debug problem of when to start up spark, WARN NativeCodeLoader will turn on.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/admin/hadoop</span><br><span class="line"><span class="comment">#export PATH=$HADOOP_HOME/bin:$PATH</span></span><br><span class="line"><span class="comment">#export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span></span><br><span class="line"><span class="comment">#export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"</span></span><br><span class="line"><span class="comment">#export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS</span><br><span class="line">WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS</span><br></pre></td></tr></table></figure>
<h3 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h3><p>Three ways to solve the problem</p>
<blockquote>
<p>install libgfortran3<br>linstall libatlas3-base libopenblas-base<br>OpenBlase</p>
</blockquote>
<ul>
<li><p>in sbt file: libraryDependencies += “com.github.fommil.netlib” % “all” % “1.1.2”</p>
<ul>
<li>-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS</li>
<li><a href="https://github.com/mridulm/netlib-java" target="_blank" rel="external">https://github.com/mridulm/netlib-java</a></li>
</ul>
</li>
<li><p>or in commandline</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install libgfortran3</span><br><span class="line">// check the libgfortran3</span><br><span class="line">$ dpkg <span class="_">-l</span> libgfortran3</span><br><span class="line">$ sudo apt-get install gfortran</span><br></pre></td></tr></table></figure>
</li>
<li><p>resolve the problem (important)</p>
<ul>
<li>refers to <a href="https://github.com/fommil/netlib-java#machine-optimised-system-libraries" target="_blank" rel="external">https://github.com/fommil/netlib-java#machine-optimised-system-libraries</a></li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libatlas3-base libopenblas-base</span><br><span class="line">sudo update-alternatives --config libblas.so.3</span><br><span class="line">sudo update-alternatives --config liblapack.so.3</span><br><span class="line">$ /etc/ld.so.conf</span><br><span class="line">add /usr/lib/libblas.so.3 &amp;  /usr/lib/liblapack.so.3</span><br><span class="line">$ sudo ldconfig</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h3><p>Resolve the debug problem of when to start up spark, WARN NativeCodeLoader will turn on.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/admin/hadoop</span><br><span class="line"><span class="comment">#export PATH=$HADOOP_HOME/bin:$PATH</span></span><br><span class="line"><span class="comment">#export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span></span><br><span class="line"><span class="comment">#export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"</span></span><br><span class="line"><span class="comment">#export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native</span></span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="Hadoop" scheme="https://snakecy.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="https://snakecy.github.io/tags/Spark/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[mac-license]]></title>
    <link href="https://snakecy.github.io/2016/02/10/mac-license/"/>
    <id>https://snakecy.github.io/2016/02/10/mac-license/</id>
    <published>2016-02-09T16:54:13.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo.</p>
<p>﻿- Open the terminal, then type in “ sudo xcodebuild -license”</p>
<ul>
<li><p>Type in “ enter”</p>
</li>
<li><p>Type in “space” for more to read, or “q” for quit</p>
</li>
<li><p>Finally, type in “agree” and enter.</p>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo.</p>
<p>﻿- Open the terminal, then type in “ ]]>
    </summary>
    
      <category term="Mac" scheme="https://snakecy.github.io/tags/Mac/"/>
    
      <category term="License" scheme="https://snakecy.github.io/categories/License/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[machine-learning-notes-1]]></title>
    <link href="https://snakecy.github.io/2016/01/16/machine-learning-notes-1/"/>
    <id>https://snakecy.github.io/2016/01/16/machine-learning-notes-1/</id>
    <published>2016-01-15T16:23:52.000Z</published>
    <updated>2016-03-14T11:48:57.000Z</updated>
    <content type="html"><![CDATA[<h3 id="Machine_learning_package_for_Python__281_29"><a href="#Machine_learning_package_for_Python__281_29" class="headerlink" title="Machine learning package for Python (1)"></a>Machine learning package for Python (1)</h3><h4 id="Basic_Requirement"><a href="#Basic_Requirement" class="headerlink" title="Basic Requirement"></a>Basic Requirement</h4><p><a href="http://blog.csdn.net/shuimuqingyi/article/details/24499057" target="_blank" rel="external">Introduce</a></p>
<h5 id="Scikit-learn"><a href="#Scikit-learn" class="headerlink" title="Scikit-learn"></a>Scikit-learn</h5><ul>
<li><p>A module for machine learning in Python, which is based on Numpy, Scipy and matplotlib.</p>
<ul>
<li><p>Scilit-learn requires:</p>
<ul>
<li><p>Python (&gt;=2.6 or &gt;=3.3)</p>
</li>
<li><p>Numpy (&gt;=1.6.1)</p>
</li>
<li><p>Scipy (&gt;=0.9)</p>
</li>
</ul>
<blockquote>
<p>For OSX installation</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pip install -U numpy scipy scikit-learn</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Before install the required tools above, we need to install homebrew to finish the installation.</p>
<ul>
<li>In mac terminal, run this<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/ruby \</span><br><span class="line"><span class="_">-e</span> <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="Machine_learning_package_for_Python__281_29"><a href="#Machine_learning_package_for_Python__281_29" class="headerlink" title="Machin]]>
    </summary>
    
      <category term="Python" scheme="https://snakecy.github.io/tags/Python/"/>
    
      <category term="Machine Learning" scheme="https://snakecy.github.io/tags/Machine-Learning/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[UCI-machine-learning-repository]]></title>
    <link href="https://snakecy.github.io/2016/01/15/UCI-machine-learning-repository/"/>
    <id>https://snakecy.github.io/2016/01/15/UCI-machine-learning-repository/</id>
    <published>2016-01-15T08:46:41.000Z</published>
    <updated>2016-03-14T11:23:16.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Datasets_Examples_for_machine_learning"><a href="#Datasets_Examples_for_machine_learning" class="headerlink" title="Datasets Examples for machine learning"></a>Datasets Examples for machine learning</h2><p>Here are the data sets from <a href="http://archive.ics.uci.edu/ml/" target="_blank" rel="external">UCI Machine Learning Repository</a> once I sorted and practiced. Some of the abstracts I summarized updated to my github <a href="https://github.com/snakecy/CUIMachineLearningRepositry" target="_blank" rel="external">CUIMachineLearningRepository</a>.</p>
<p>Example:</p>
<h3 id="Image_Segmentation"><a href="#Image_Segmentation" class="headerlink" title="Image Segmentation"></a>Image Segmentation</h3><ol>
<li>Data set website<br><a href="http://archive.ics.uci.edu/ml/datasets/Image+Segmentation" target="_blank" rel="external">http://archive.ics.uci.edu/ml/datasets/Image+Segmentation</a></li>
<li>Datasets describe<br>【1】The data used in our experiments were collected by Vision Group, University of Massachusetts.【2】We used to classify the image.【3】The instances were drawn randomly from a database of 7 outdoor images. The images were hand segmented to create a classification for every pixel. Each instance is a 3x3 region. Number of Attributes has 19 continuous attributes, each attribute can describes as region-centroid-col、region-centroid-row、region-pixel-count、short-line-density-5、short-line-density-2、 vedge-mean、vegde-sd、hedge-mean、hedge-sd、intensity-mean、rawred-mean、rawblue-mean、rawgreen-mean、exred-mean、exblue-mean、exgreen-mean、value-mean、saturatoin-mean、hue-mean.【4】The database has 2310 samples, respectively belong to training with 210 samples and testing with 2100 samples. The categories of network system include seven categories, as shown in Table 1.</li>
</ol>
<h5 id="Table_1_Category_Distribution_of_Network_System"><a href="#Table_1_Category_Distribution_of_Network_System" class="headerlink" title="Table 1 Category Distribution of Network System"></a>Table 1 Category Distribution of Network System</h5><table>
<thead>
<tr>
<th style="text-align:left">Invasion</th>
<th style="text-align:left">Training</th>
<th style="text-align:left">Testing</th>
<th style="text-align:left">Total Number of Samples</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Brickface</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">sky</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">Foliage</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">Cement</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">window</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">Path</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">grass</td>
<td style="text-align:left">30</td>
<td style="text-align:left">300</td>
<td style="text-align:left">330</td>
</tr>
<tr>
<td style="text-align:left">Total number of samples in total</td>
<td style="text-align:left">210</td>
<td style="text-align:left">2100</td>
<td style="text-align:left">2310</td>
</tr>
</tbody>
</table>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Datasets_Examples_for_machine_learning"><a href="#Datasets_Examples_for_machine_learning" class="headerlink" title="Datasets Example]]>
    </summary>
    
      <category term="Java" scheme="https://snakecy.github.io/tags/Java/"/>
    
      <category term="Python" scheme="https://snakecy.github.io/tags/Python/"/>
    
      <category term="Matlab" scheme="https://snakecy.github.io/tags/Matlab/"/>
    
      <category term="algorithm" scheme="https://snakecy.github.io/categories/algorithm/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Install NoSQL Database]]></title>
    <link href="https://snakecy.github.io/2016/01/13/nosql-database/"/>
    <id>https://snakecy.github.io/2016/01/13/nosql-database/</id>
    <published>2016-01-12T18:25:57.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>NoSQL database for a key-value DB Redis</p>
<ul>
<li><p>Quick Start <a href="http://redis.io/topics/quickstart" target="_blank" rel="external">Redis</a></p>
</li>
<li><p>use the key value DB (redis)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install redis-server</span><br><span class="line">to <span class="built_in">test</span> redis using: &gt;&gt; redis-cli   to enter</span><br><span class="line"><span class="keyword">then</span> : 127.0.0.1:6379&gt; <span class="built_in">set</span> <span class="built_in">test</span> 1</span><br><span class="line">&gt; get <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Or download the redis from website</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-3.0.2.tar.gz</span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>Or download</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/redis-stable.tar.gz</span><br><span class="line">tar xvzf redis-stable.tar.gz</span><br><span class="line"><span class="built_in">cd</span> redis-stable</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
</li>
<li><p>Update the redis-server</p>
<ul>
<li><p>first way</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:chris-lea/redis-server</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install redis-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>another way to do this update</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y python-software-properties</span><br><span class="line">sudo add-apt-repository -y ppa:rwky/redis</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y redis-server</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>NoSQL database for a key-value DB Redis</p>
<ul>
<li><p>Quick Start <a href="http://redis.io/topics/quickstart">Redis</a></p>
</li>
<li><p>use the key value DB (redis)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install redis-server</span><br><span class="line">to <span class="built_in">test</span> redis using: &gt;&gt; redis-cli   to enter</span><br><span class="line"><span class="keyword">then</span> : 127.0.0.1:6379&gt; <span class="built_in">set</span> <span class="built_in">test</span> 1</span><br><span class="line">&gt; get <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Or download the redis from website</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-3.0.2.tar.gz</span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="NoSQL" scheme="https://snakecy.github.io/tags/NoSQL/"/>
    
      <category term="Redis" scheme="https://snakecy.github.io/tags/Redis/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Json parsered by Java]]></title>
    <link href="https://snakecy.github.io/2016/01/13/json-eclipse/"/>
    <id>https://snakecy.github.io/2016/01/13/json-eclipse/</id>
    <published>2016-01-12T17:26:05.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Describe how to parser Json flows in (eclipse)  Java, also in Scala</p>
<h2 id="Json_in_Java"><a href="#Json_in_Java" class="headerlink" title="Json in Java"></a>Json in Java</h2><p>Json-lib must contain the jars blowing ( versions not limited)</p>
<ul>
<li><p><a href="http://www.studytrails.com/java/json/java-org-json.jsp" target="_blank" rel="external">Java-org-json</a></p>
</li>
<li><p>Json-lib</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">commons-beanutils-1.7.0.jar  or commons-beanutils-1.9.2.jar</span><br><span class="line">commons-collections-3.1.jar  or commons-collections-3.2.1.jar</span><br><span class="line">commons-lang-2.5.jar  or commons-lang-2.6.jar</span><br><span class="line">commons-logging-1.1.1.jar  or commons-logging-1.2.jar</span><br><span class="line">ezmorph-1.0.3.jar  or ezmorph-1.0.6.jar</span><br><span class="line">json-lib-2.2.2-jdk15.jar  or json-lib-2.4-jdk15.jar</span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p><a href="http://www.cnblogs.com/zhenjing/p/json-smart.html" target="_blank" rel="external">Json-smart</a></p>
<ul>
<li>Compare with each json jar package <a href="https://code.google.com/p/json-smart/wiki/FeaturesTests" target="_blank" rel="external">compare</a></li>
</ul>
</li>
<li><p>simple-json</p>
</li>
<li><p>org.json</p>
</li>
<li><p>example</p>
<ul>
<li><a href="http://crunchify.com/how-to-write-json-object-to-file-in-java/" target="_blank" rel="external">http://crunchify.com/how-to-write-json-object-to-file-in-java/</a></li>
<li><a href="http://crunchify.com/how-to-read-json-object-from-file-in-java/" target="_blank" rel="external">http://crunchify.com/how-to-read-json-object-from-file-in-java/</a></li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reference:</span></span><br><span class="line">&gt; json格式如下：&#123;<span class="string">"response"</span>:&#123;<span class="string">"data"</span>:[&#123;<span class="string">"address"</span>:<span class="string">"南京市游乐园"</span>,<span class="string">"province"</span>:<span class="string">"江苏"</span>,<span class="string">"district"</span>:<span class="string">"玄武区"</span>,<span class="string">"city"</span>:<span class="string">"南京"</span>&#125;]&#125;,<span class="string">"status"</span>:<span class="string">"ok"</span>&#125;</span><br><span class="line">Result： 江苏 南京 玄武区 南京市游乐园</span><br><span class="line">﻿</span><br><span class="line">JSONObject dataJson=new JSONObject(<span class="string">"Json data"</span>);</span><br><span class="line">JSONObject response=dataJson.getJSONObject(<span class="string">"response"</span>);</span><br><span class="line">JSONArray data=response.getJSONArray(<span class="string">"data"</span>);</span><br><span class="line">JSONObject info=data.getJSONObject(0);</span><br><span class="line">String province=info.getString(<span class="string">"province"</span>);</span><br><span class="line">String city=info.getString(<span class="string">"city"</span>);</span><br><span class="line">String district=info.getString(<span class="string">"district"</span>);</span><br><span class="line">String address=info.getString(<span class="string">"address"</span>);</span><br><span class="line">System.out.println(province+city+district+address);</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<p>Describe how to parser Json flows in (eclipse)  Java, also in Scala</p>
<h2 id="Json_in_Java"><a href="#Json_in_Java" class="headerlink" title="Json in Java"></a>Json in Java</h2><p>Json-lib must contain the jars blowing ( versions not limited)</p>
<ul>
<li><p><a href="http://www.studytrails.com/java/json/java-org-json.jsp">Java-org-json</a></p>
</li>
<li><p>Json-lib</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">commons-beanutils-1.7.0.jar  or commons-beanutils-1.9.2.jar</span><br><span class="line">commons-collections-3.1.jar  or commons-collections-3.2.1.jar</span><br><span class="line">commons-lang-2.5.jar  or commons-lang-2.6.jar</span><br><span class="line">commons-logging-1.1.1.jar  or commons-logging-1.2.jar</span><br><span class="line">ezmorph-1.0.3.jar  or ezmorph-1.0.6.jar</span><br><span class="line">json-lib-2.2.2-jdk15.jar  or json-lib-2.4-jdk15.jar</span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Java" scheme="https://snakecy.github.io/tags/Java/"/>
    
      <category term="Json" scheme="https://snakecy.github.io/tags/Json/"/>
    
      <category term="Eclipse" scheme="https://snakecy.github.io/tags/Eclipse/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[API configure with Php-r-sparkr]]></title>
    <link href="https://snakecy.github.io/2016/01/12/php-r-sparkr/"/>
    <id>https://snakecy.github.io/2016/01/12/php-r-sparkr/</id>
    <published>2016-01-12T09:25:06.000Z</published>
    <updated>2016-03-14T09:32:33.000Z</updated>
    <content type="html"><![CDATA[<blockquote>
<hr>
<p>PHP configure</p>
<hr>
</blockquote>
<ul>
<li><p>How to install the nignx on Ubuntu 10.04?<br>Append the appropriate stanza to /etc/apt/sources.list. The Pgp page expalins the signing of th nignx.org released packaging.</p>
<ul>
<li><p>shell script</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deb http://nginx.org/packages/ubuntu/ lucid nginx</span><br><span class="line">deb-src http://nginx.org/packages/ubuntu/ lucid nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>then do</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="_">-s</span></span><br><span class="line">nginx=stable <span class="comment"># use nginx=development for latest development version</span></span><br><span class="line">add-apt-repository ppa:nginx/<span class="variable">$nginx</span></span><br><span class="line">apt-get update</span><br><span class="line">apt-get install nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Then finished. Ref. at website<br>(<a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/install/" target="_blank" rel="external">https://www.nginx.com/resources/wiki/start/topics/tutorials/install/</a>)</p>
</li>
</ul>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>PHP Server Nginx</p>
<ul>
<li>$ cd nginx/html</li>
<li>port : 80 –&gt; public port: 8181</li>
<li>example-data.cloudapp.net:8181/index.html</li>
</ul>
</li>
<li><p>Docker</p>
<ul>
<li>$ curl -sSL https//get.docker.com/ | sh</li>
<li>$ sudo docker run hello-world</li>
<li>Add a user with ‘sudo’<ul>
<li>sudo user -aG docker admin</li>
</ul>
</li>
<li>Restart the server<ul>
<li>$ docker run hello-world</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<hr>
<p>R installation</p>
<hr>
</blockquote>
<ul>
<li>R Tutorial</li>
<li><p>Update R on Ubuntu</p>
<ul>
<li>$ sudo gedit /etc/apt/sources.list –&gt; open the .list file<ul>
<li>sudo vi /etc/apt/sources.list</li>
<li>#sudo apt-get install gedit</li>
<li><a href="http://cran.r-project.org/becin/linux/ubuntu/" target="_blank" rel="external">http://cran.r-project.org/becin/linux/ubuntu/</a></li>
</ul>
</li>
<li>add the following line into source.list<ul>
<li>deb <a href="http://cran.cnr.berkeley.edu/bin/linux/ubuntu/" target="_blank" rel="external">http://cran.cnr.berkeley.edu/bin/linux/ubuntu/</a> trusty/</li>
<li><h1 id="trusty_for_Ubuntu_14-04"><a href="#trusty_for_Ubuntu_14-04" class="headerlink" title="trusty for Ubuntu 14.04"></a>trusty for Ubuntu 14.04</h1></li>
</ul>
</li>
<li><p>Secure apt, when u see the gpg secure problem, just do the following lines</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$sudo</span> apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9</span><br><span class="line"><span class="variable">$gpg</span> --keyserver keyserver.ubuntu.com --recv-key E084DAB9</span><br><span class="line"><span class="variable">$gpg</span> <span class="_">-a</span> --export E084DAB9 | sudo apt-key add -</span><br></pre></td></tr></table></figure>
</li>
<li><p>Then, perform this command</p>
<ul>
<li>sudo apt-get update</li>
<li>sudo apt-get install r-base r-base-dev</li>
</ul>
</li>
</ul>
</li>
<li><p>Import library dplyr &amp; FeatureHashing</p>
<ul>
<li>Request R version &gt;3.1.2<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ R</span><br><span class="line">&gt; install.packages(<span class="string">"dplyr"</span>)</span><br><span class="line">&gt; library(dplyr)</span><br><span class="line">&gt; install.packages(<span class="string">"FeatureHashing"</span>)</span><br><span class="line">&gt; library(FeatureHashing)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<blockquote>
<hr>
<p>R library</p>
<hr>
</blockquote>
<ul>
<li><p>library</p>
<ul>
<li>Matrix</li>
<li>glmnt</li>
<li>FeatureHashing<ul>
<li>Important, the FeatureHashing’s latest version is 0.9, which default parameter transpose is TRUE (but in 0.8 version is FALSE)</li>
</ul>
</li>
<li>glmnet</li>
<li>dplyr</li>
<li>ROC <a href="http://web.expasy.org/pROC/" target="_blank" rel="external">http://web.expasy.org/pROC/</a>  <ul>
<li>install.packages(“pROC”)</li>
<li>library(pROC)</li>
</ul>
</li>
<li>“josnlite” package, parser json file<ul>
<li>A smart json encoder in R <a href="https://www.opencpu.org/posts/jsonlite-a-smarter-json-encoder/" target="_blank" rel="external">https://www.opencpu.org/posts/jsonlite-a-smarter-json-encoder/</a></li>
<li>install.packages(“jsonlite”, repos=”<a href="http://cran.r-project.org" target="_blank" rel="external">http://cran.r-project.org</a>“)</li>
<li>install.packages(“curl”)</li>
</ul>
</li>
<li>“lubridate”, parser date</li>
<li>“json_decode”, function to parser json into array</li>
<li><p>R compare script (* important)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = data.frame(A=c(5,6,7,8), B=c(1,7,5,9))</span><br><span class="line">with(df,df[A&gt;B,])</span><br></pre></td></tr></table></figure>
</li>
<li><p>Censored regression in r</p>
<ul>
<li>Each steps <a href="http://stats.stackexchange.com/questions/149091/censored-regression-in-r" target="_blank" rel="external">http://stats.stackexchange.com/questions/149091/censored-regression-in-r</a></li>
<li>Package <a href="https://cran.r-project.org/web/packages/AER/" target="_blank" rel="external">https://cran.r-project.org/web/packages/AER/</a></li>
<li>How to install packages<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; install.packages(<span class="string">"AER"</span>, lib = <span class="string">"/my/own/R-packages/"</span>)</span><br><span class="line">&gt; library(<span class="string">"AER"</span>, lib.loc=<span class="string">"/my/own/R-packages/"</span>)</span><br><span class="line">Ref http://www.math.usask.ca/~longhai/software/installrpkg.html</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<hr>
<p>PHP call R API</p>
<hr>
</blockquote>
<ul>
<li><p>API part</p>
<ul>
<li><p>PHP API</p>
<ul>
<li>API url <a href="http://example-rtb.cloudapp.net:8181/example/api/predict.php" target="_blank" rel="external">http://example-rtb.cloudapp.net:8181/example/api/predict.php</a></li>
<li>PHP calling function methods</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">call_user_func()</span><br><span class="line">call_user_func(<span class="string">'a'</span>, <span class="string">"111"</span>, <span class="string">"222"</span>)</span><br><span class="line">call_user_func_array()</span><br><span class="line">call_user_func_array(<span class="string">'a'</span>, array(<span class="string">"111"</span>, <span class="string">"222"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>RESTful API based OpenCPU</p>
<ul>
<li>example prediction API<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ time curl http://localhost:7509/ocpu/library/exampleApi/R/predict_api/json -H <span class="string">"Content-Type:application/json"</span> <span class="_">-d</span> <span class="string">'&#123;"request":["http://*.cloudapp.net:8181/json/req.txt"]&#125;'</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Install opencpu on Ubuntu cloud server</p>
<ul>
<li>Recommended on Ubuntu 14.04</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#requires ubuntu 14.04 (trusty)</span></span><br><span class="line">sudo add-apt-reporitory -y ppa:opencpu/opencpu-1.5</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br><span class="line"><span class="comment">#install opencpu server</span></span><br><span class="line">sudo apt-get install -y opencpu</span><br><span class="line"><span class="comment"># optional</span></span><br><span class="line">sudo apt-get isntall -y rstudio-server</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>R command</p>
<ul>
<li><p>Local</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/sparkR --packages com.databricks:spark-csv_2.11:1.2.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>Standalone</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/sparkR --master spark://example-data01:7077 --packages com.databricks:spark-csv_2.11:1.2.0</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>SparkR MLlib</p>
<ul>
<li>An exampel for sparkR MLlib<ul>
<li>Ref <a href="https://github.com/AlbanPhelip/SparkR-example" target="_blank" rel="external">https://github.com/AlbanPhelip/SparkR-example</a></li>
</ul>
</li>
<li>Only the glm() can be used in sparkR<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/sparkR --master spark://example-data01:7077 --packages com.databricks:spark-csv_2.11:1.2.0 /home/admin/Rscript_model_<span class="built_in">test</span>/train_sparkr.R hdfs://masters/Rscript_model/data.txt hdfs://masters/Rscript_model/model.Rds</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<blockquote>
<hr>
<p>R on SparkR  tutorials for Big Data analysis and Machine Learning as IPython/Jupyter notebooks</p>
<h2 id="https_3A//github-com/jadianes/spark-r-notebooks"><a href="#https_3A//github-com/jadianes/spark-r-notebooks" class="headerlink" title="https://github.com/jadianes/spark-r-notebooks"></a><a href="https://github.com/jadianes/spark-r-notebooks" target="_blank" rel="external">https://github.com/jadianes/spark-r-notebooks</a></h2><hr>
<p>A good example for R app</p>
<hr>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">http://blog.fens.me/r-app-china-weather/</span><br><span class="line">RandomForest <span class="keyword">in</span> R with parallel trainning.</span><br><span class="line"><span class="comment"># the parallel computing by RandomForest</span></span><br><span class="line">library(randomForest)</span><br><span class="line"> cl &lt;- makeCluster(4)</span><br><span class="line"> registerDoParallel(cl)</span><br><span class="line"> rf &lt;- foreach(ntree=rep(25000, 4),</span><br><span class="line">                  .combine=combine,</span><br><span class="line">                  .packages=<span class="string">'randomForest'</span>) %dopar%</span><br><span class="line">          randomForest(Species~., data=iris, ntree=ntree)</span><br><span class="line">stopCluster(cl)</span><br></pre></td></tr></table></figure>
<blockquote>
<hr>
<p>SparkR configure</p>
<hr>
</blockquote>
<p>SparkR is an R package that provides a light-weight frontend to use Apache Spark from R</p>
<ul>
<li>Ref <a href="https://github.com/amplab-extras/SparkR-pkg" target="_blank" rel="external">https://github.com/amplab-extras/SparkR-pkg</a> | <a href="http://amplab-extras.github.io/SparkR-pkg/" target="_blank" rel="external">http://amplab-extras.github.io/SparkR-pkg/</a></li>
<li><p>Configure the sparkR environment</p>
<ul>
<li>Required<ul>
<li>openjdk 7, R</li>
</ul>
</li>
<li>Steps for set up<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo R</span><br><span class="line">install.packages(<span class="string">"rJava"</span>)</span><br><span class="line">install.packages(<span class="string">"devtools"</span>, dependencies = TRUE)</span><br><span class="line"><span class="comment"># after install rJava &amp; devtools</span></span><br><span class="line">library(devtools)</span><br><span class="line">install_github(<span class="string">"amplab-extras/SparkR-pkg"</span>, subdir=<span class="string">"pkg"</span>)</span><br><span class="line"><span class="comment"># Resolve</span></span><br><span class="line"><span class="comment"># sudo apt-get install r-cran-rjava</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Required</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libxml2-dev</span><br><span class="line">sudo apt-get install libcurl4-openssl-dev</span><br><span class="line">sudo apt-get install libcurl4-gnutls-dev</span><br><span class="line">sudo apt-get install curl</span><br><span class="line">/etc/apt/source.list</span><br><span class="line">  <span class="comment">#deb http://cran.rstudio.com/bin/linux/ubuntu trusty/</span></span><br><span class="line">sudo apt-get install libssl-dev</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>Sort the SparkR</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">./bin/sparkR --packages com.databricks:spark-csv_2.11:1.2.0</span><br><span class="line"> sc &lt;- sparkR.init(sparkPackages=<span class="string">"com.databricks:spark-csv_2.11:1.2.0"</span>)</span><br><span class="line">sc &lt;- sparkR.init(master=<span class="string">"spark://example-data01:7077"</span>, sparkEnvir=list(spark.executor.memory=<span class="string">"10g"</span>, spark.cores.max=<span class="string">"4"</span>), sparkPackages=<span class="string">"com.databricks:spark-csv_2.11:1.2.0"</span> )</span><br><span class="line">sqlContext &lt;- sparkRSQL.init(sc)</span><br><span class="line">dataT &lt;- read.df(sqlContext, <span class="string">"hdfs://masters/Rscript_model/data.txt"</span>,<span class="string">"com.databricks.spark.csv"</span>,header=<span class="string">"true"</span>,delimiter=<span class="string">"\t"</span>)</span><br><span class="line">on example-data01: dataT &lt;- read.df(sqlContext, <span class="string">"/home/admin/data/data.txt"</span>,<span class="string">"com.databricks.spark.csv"</span>,header=<span class="string">"true"</span>,delimiter=<span class="string">"\t"</span>, transpose = <span class="string">"true"</span>, is.dgCMatrix = <span class="string">"false"</span>)</span><br><span class="line">Ref script</span><br><span class="line">dataT &lt;- read.df(sqlContext, <span class="string">"/home/admin/data/data.txt"</span>,<span class="string">"com.databricks.spark.csv"</span>,header=<span class="string">"true"</span>,delimiter=<span class="string">"\t"</span>)</span><br><span class="line">head(select(dataT,dataT<span class="variable">$is_win</span>))</span><br><span class="line"><span class="built_in">test</span> &lt;- structure(dataT, package=<span class="string">"SparkR"</span>)</span><br><span class="line">dataT &lt;- read.table(sqlContext, <span class="string">"hdfs://masters/Rscript_model/data.txt"</span>,<span class="string">"com.databricks.spark.csv"</span>,header=<span class="string">"true"</span>,delimiter=<span class="string">"\t"</span>)</span><br><span class="line"><span class="built_in">test</span> &lt;- cbind(select(dataT, <span class="string">"is_win"</span>), select(dataT, <span class="string">"days"</span>), select(dataT, <span class="string">"hours"</span>), select(dataT, <span class="string">"exchange_id"</span>), select(dataT, <span class="string">"app_id"</span>), select(dataT, <span class="string">"publiser_id"</span>), select(dataT, <span class="string">"bidfloor"</span>), select(dataT, <span class="string">"w"</span>), select(dataT, <span class="string">"h"</span>), select(dataT, <span class="string">"os"</span>), select(dataT, <span class="string">"Osv"</span>), select(dataT, <span class="string">"model"</span>), select(dataT, <span class="string">"connectiontype"</span>), select(dataT,<span class="string">"country"</span>), select(dataT, <span class="string">"ua"</span>), select(dataT,<span class="string">"carrier"</span>), select(dataT, <span class="string">"js"</span>), select(dataT, <span class="string">"user"</span>), select(dataT, <span class="string">"carriername"</span>), select(dataT, <span class="string">"app_cat"</span>), select(dataT,<span class="string">"btype"</span>), select(dataT,<span class="string">"mimes"</span>), select(dataT,<span class="string">"badv"</span>), select(dataT,<span class="string">"bcat"</span>))</span><br><span class="line">as.data.frame(<span class="built_in">test</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<hr>
<p>Output Format using R</p>
<hr>
</blockquote>
<ul>
<li><p>pdf  format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pdf(file=<span class="string">"myplot.pdf"</span>)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure>
</li>
<li><p>jpeg format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">setwd(<span class="string">"path"</span>)</span><br><span class="line">jpeg(file=<span class="string">"myplot.jpeg"</span>)</span><br><span class="line">plot(1:10)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure>
</li>
<li><p>png format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">png(file=<span class="string">"myplot.png"</span>, <span class="built_in">bg</span>=<span class="string">"transparent"</span>)</span><br><span class="line">dev.off()</span><br><span class="line"><span class="comment">#View the png on Ubuntu, by using "gthumb"</span></span><br><span class="line"><span class="comment">#  sudo apt-get install gthumb</span></span><br><span class="line"><span class="comment">#  $gthumb myplot.png</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>bmp format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bmp(<span class="string">"myplot.bmp"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>PostScript format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">postscript(<span class="string">"myplot.ps"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Windows image file format</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">win.metafile(<span class="string">"myplot.ps"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<hr>
<p>PHP configure</p>
<hr>
</blockquote>
<ul>
<li><p>How to install the nignx on Ubuntu 10.04?<br>Append the appropriate stanza to /etc/apt/sources.list. The Pgp page expalins the signing of th nignx.org released packaging.</p>
<ul>
<li><p>shell script</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deb http://nginx.org/packages/ubuntu/ lucid nginx</span><br><span class="line">deb-src http://nginx.org/packages/ubuntu/ lucid nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>then do</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="_">-s</span></span><br><span class="line">nginx=stable <span class="comment"># use nginx=development for latest development version</span></span><br><span class="line">add-apt-repository ppa:nginx/<span class="variable">$nginx</span></span><br><span class="line">apt-get update</span><br><span class="line">apt-get install nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>Then finished. Ref. at website<br>(<a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/install/">https://www.nginx.com/resources/wiki/start/topics/tutorials/install/</a>)</p>
</li>
</ul>
</li>
</ul>]]>
    
    </summary>
    
      <category term="R" scheme="https://snakecy.github.io/tags/R/"/>
    
      <category term="SparkR" scheme="https://snakecy.github.io/tags/SparkR/"/>
    
      <category term="PHP" scheme="https://snakecy.github.io/tags/PHP/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HDFS configure with Zookeeper (02)]]></title>
    <link href="https://snakecy.github.io/2016/01/12/hdfs-spark-2/"/>
    <id>https://snakecy.github.io/2016/01/12/hdfs-spark-2/</id>
    <published>2016-01-12T07:15:04.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Construct the platform for Big Data project</p>
<h2 id="Configure_Zookeeper"><a href="#Configure_Zookeeper" class="headerlink" title="Configure Zookeeper"></a>Configure Zookeeper</h2><ul>
<li>on each server, configure the java environment<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf zookeeper-3.4.6.tar.gz</span><br><span class="line">$ mv zookeeper-3.4.6 zookeeper</span><br><span class="line">$ <span class="built_in">cd</span> zookeeper/conf</span><br><span class="line">$ cp zoo_sample.cfg zoo.cfg</span><br><span class="line">$ vi zoo.cfg</span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<table>
<thead>
<tr>
<th>Server role</th>
<th>example-data01（namenode1）</th>
<th>example-data02（namenode2）</th>
<th>example-data03（datanode1）</th>
<th style="text-align:right">example-data04（datanode2）</th>
</tr>
</thead>
<tbody>
<tr>
<td>NameNode</td>
<td>YES</td>
<td>YES</td>
<td>NO</td>
<td style="text-align:right">NO</td>
</tr>
<tr>
<td>DataNode</td>
<td>NO</td>
<td>NO</td>
<td>YES</td>
<td style="text-align:right">YES</td>
</tr>
<tr>
<td>JournalNode</td>
<td>YES</td>
<td>YES</td>
<td>YES</td>
<td style="text-align:right">NO</td>
</tr>
<tr>
<td>ZooKeeper</td>
<td>YES</td>
<td>YES</td>
<td>YES</td>
<td style="text-align:right">NO</td>
</tr>
<tr>
<td>ZKFC</td>
<td>YES</td>
<td>YES</td>
<td>NO</td>
<td style="text-align:right">NO</td>
</tr>
</tbody>
</table>
<ul>
<li>8080 =&gt; example-data01:50070</li>
<li>8000 =&gt; example-data02:50070</li>
</ul>
<h3 id="Hadoop_configure"><a href="#Hadoop_configure" class="headerlink" title="Hadoop configure"></a>Hadoop configure</h3><ul>
<li><p>hosts</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">*.*.*.*  example-data01</span><br><span class="line">*.*.*.*  example-data02</span><br><span class="line">*.*.*.*  example-data03</span><br><span class="line">*.*.*.*  example-data04</span><br></pre></td></tr></table></figure>
</li>
<li><p>$ vi ~/.bashrc</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim ~/.bashrc</span></span><br><span class="line"><span class="built_in">export</span> ZOO_HOME=/home/admin/zookeeper</span><br><span class="line"><span class="built_in">export</span> ZOO_LOG_DIR=/home/admin/zookeeper/logs</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOO_HOME</span>/bin</span><br><span class="line"><span class="comment"># source ~/.bashrc</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>$ mkdir -p /data/hadoop/zookeeper/{data,logs}</p>
</li>
<li>$ cp ~/zookeeper/conf/zoo_sample.cfg ~/zookeeper/conf/zoo.cfg</li>
<li><p>$ vim zoo.cfg</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /home/admin/zookeeper/conf/zoo.cfg</span></span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/admin/zookeeper/data</span><br><span class="line">clientPort=2181</span><br><span class="line">server.1=example-data01:2888:3888</span><br><span class="line">server.2=example-data02:2888:3888</span><br><span class="line">server.3=example-data03:2888:3888</span><br></pre></td></tr></table></figure>
</li>
<li><p>$ create myid in zkData file   -&gt; echo 1 &gt; myid</p>
</li>
<li>$ scp -r zookeeper/* admin@example-data02:~  -&gt; echo 2 &gt; myid</li>
<li>$ scp -r zookeeper/* admin@example-data03:~   -&gt; echo 3 &gt; myid</li>
<li>$ cp ~/zookeeper to each server ( example-data02, example-data03)</li>
<li>on example-data01<ul>
<li>check status by using  </li>
<li>$  ./bin/zkCli.sh -server example-data01:2181</li>
<li>$  or ./bin/zkCli.sh -server example-data02:2181</li>
<li>exit by using “quit”</li>
</ul>
</li>
<li>on each node to perform<ul>
<li>./bin/zkServer.sh start</li>
<li>./bin/zkServer.sh status</li>
</ul>
</li>
</ul>
<h4 id="Configure"><a href="#Configure" class="headerlink" title="Configure"></a>Configure</h4><pre><code>- example-data01(Namenode) example-data02(Sec-namenode) example-data03(datanode)  example-data04 (datanode)
</code></pre><h4 id="On_example-data01"><a href="#On_example-data01" class="headerlink" title="On example-data01"></a>On example-data01</h4><ul>
<li><p>Step 1:</p>
<ul>
<li>vim ~/.bashrc ( then copy the ~/.bashrc to example-data02( namenode) &amp; example-data03 (datanode)</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># java configure</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-oracle</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$CLASSPATH</span>:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/jre/lib</span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop configure</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/admin/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#zookeeper configure</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> ZOO_HOME=/home/admin/zookeeper</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOO_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> ZOO_LOG_DIR=/home/admin/zookeeper/logs</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib/native"</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_PID_DIR=/home/admin/hadoop/pids</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Step 2:</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /home/admin/hadoop/&#123;pids,storage&#125;</span><br><span class="line">$ mkdir -p /home/admin/hadoop/storage/&#123;hdfs,tmp,journal&#125;</span><br><span class="line">$ mkdir -p /home/admin/hadoop/storage/hdfs/&#123;name,data&#125;</span><br><span class="line"><span class="keyword">in</span> example-data03 &amp; example-data04</span><br><span class="line">$ mkdir -p /datadriver/hdfs/data</span><br><span class="line">$ sudo chown admin /datadriver/hdfs/data/</span><br></pre></td></tr></table></figure>
<ul>
<li>Step 3:</li>
</ul>
<blockquote>
<p>configure the core-site.xml, hadoop-env.sh, hdfs-site.xml</p>
</blockquote>
<ul>
<li>configure core-site.xml</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://masters&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;file:/home/admin/hadoop/storage/tmp&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;example-data01:2181,example-data02:2181,example-data03:2181&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.native.lib&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">configure  hdfs-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;masters&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.namenodes.masters&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn1,nn2&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;file:///home/admin/hadoop/storage/hdfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">//                &lt;value&gt;file:/home/admin/hadoop/storage/hdfs/data&lt;/value&gt;</span><br><span class="line">                &lt;value&gt;file:///datadriver/hdfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.rpc-address.masters.nn1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;example-data01:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.http-address.masters.nn1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;example-data01:50070&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.rpc-address.masters.nn2&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;example-data02:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.http-address.masters.nn2&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;example-data02:50070&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;qjournal://example-data01:8485;example-data02:8485;example-data03:8485/masters&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/admin/hadoop/storage/journal&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;sshfence(hdfs)</span><br><span class="line">                shell(/bin/<span class="literal">true</span>)&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/admin/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;30000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.client.failover.proxy.provider.masters&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>configure hadoop-env.sh</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-oracle</span><br></pre></td></tr></table></figure>
<ul>
<li>configure slaves</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">example-data03</span><br><span class="line">example-data04</span><br></pre></td></tr></table></figure>
<ul>
<li>Step 4:</li>
</ul>
<blockquote>
<p>scp hadoop to each node ( example-data02, example-data03, example-data04)</p>
</blockquote>
<ul>
<li>Step 5:</li>
</ul>
<blockquote>
<p>Setup the  HDFS Cluster with ZooKeeper Using Demo (example)</p>
</blockquote>
<ul>
<li><p>on the namenode1 (example-data01)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>
</li>
<li><p>on each zookeeper node</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop-daemon.sh start journalnode</span><br><span class="line">// $ ./sbin/hadoop-daemons.sh --hostnames <span class="string">'example-data01 example-data02 example-data03'</span> start journalnode  // this <span class="built_in">command</span> is used to start the journalnode of zookeeper</span><br></pre></td></tr></table></figure>
</li>
<li><p>on the namenode1 (example-data01)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>on the namenode1 (example-data01)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
</li>
<li><p>on namenode2 (example-data02)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>
</li>
<li><p>on namenode2 (example-data02)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
</li>
<li><p>on the two namenode (namenode1, namenode2)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./sbin/hadoop-daemon.sh start zkfc</span><br></pre></td></tr></table></figure>
</li>
<li><p>on the all datanode (datanode1, datanode2)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
</li>
<li><p>still now, we can see the following name on namenode1 (example-data01)</p>
<blockquote>
<p>QuorumPeerMain, NameNode, DFSZKFailoverController(basically), JournalNode</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>Step 6: Testing the HDFS’s  function<br>-</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  login on web</span></span><br><span class="line">example-data01: namenode (active)  =&gt; example-data01:9000</span><br><span class="line">website: example-hadoop.cloudapp.net:8080</span><br><span class="line">example-data02: namenode (standby)  =&gt; example-data02:9000</span><br><span class="line">website: example-hadoop.cloudapp.net:8000</span><br><span class="line"><span class="comment"># $ hadoop-daemon.sh start namenode</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Step 7: Import , excute on namenode1 (example-data01)</p>
<ul>
<li><p>Before Starting HDFS , Formating the zookeeper</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs zkfc -formatZK</span><br><span class="line">Start the HDFS  --&gt; $ <span class="built_in">cd</span> /home/admin/hadoop &amp;&amp; sbin/start-dfs.sh</span><br><span class="line">Stop the HDFS  --&gt; $ <span class="built_in">cd</span> /home/admin/hadoop &amp;&amp; sbin/stop-dfs.sh</span><br><span class="line">$ start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>check the status on two namenode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs haadmin -getServiceState nn1 --&gt; active</span><br><span class="line">$ hdfs haadmin -getServiceState nn2 --&gt; standby</span><br></pre></td></tr></table></figure>
</li>
<li><p>when the stop-dfs.sh turn to <a href="http://taoo.iteye.com/blog/1730406" target="_blank" rel="external">error</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> HADOOP_PID_DIR=/home/hadoop/pids</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>hdfs dfsadmin -report</p>
</li>
</ul>
<h3 id="Spark_on_Yarn_Reference"><a href="#Spark_on_Yarn_Reference" class="headerlink" title="Spark on Yarn Reference"></a><a href="http://wuchong.me/blog/2015/04/04/spark-on-yarn-cluster-deploy/" target="_blank" rel="external">Spark on Yarn Reference</a></h3><p>configure additional two file<br>yarn-site.xml &amp; maperd-site.xml</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Construct the platform for Big Data project</p>
<h2 id="Configure_Zookeeper"><a href="#Configure_Zookeeper" class="headerlink" title="Configure Zookeeper"></a>Configure Zookeeper</h2><ul>
<li>on each server, configure the java environment<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf zookeeper-3.4.6.tar.gz</span><br><span class="line">$ mv zookeeper-3.4.6 zookeeper</span><br><span class="line">$ <span class="built_in">cd</span> zookeeper/conf</span><br><span class="line">$ cp zoo_sample.cfg zoo.cfg</span><br><span class="line">$ vi zoo.cfg</span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Hadoop" scheme="https://snakecy.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="https://snakecy.github.io/tags/Spark/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HDFS configure with Zookeeper (01)]]></title>
    <link href="https://snakecy.github.io/2016/01/12/hdfs-spark-1/"/>
    <id>https://snakecy.github.io/2016/01/12/hdfs-spark-1/</id>
    <published>2016-01-12T07:14:59.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Construct the platform for Big Data project</p>
<h2 id="Build_HardDisk_RAID0"><a href="#Build_HardDisk_RAID0" class="headerlink" title="Build HardDisk RAID0"></a>Build HardDisk RAID0</h2><p>This paragraph describes the HDFS configure progress on Azure Cloud Server. You need have a azure account to login in and purchase the platform you will perform on. Here is my platform construction details to share with you.</p>
<a id="more"></a>
<ul>
<li>Unbuntu 14.0 LTS</li>
</ul>
<h3 id="lvm2"><a href="#lvm2" class="headerlink" title="lvm2"></a>lvm2</h3><ul>
<li>command <a href="http://linux.about.com/library/cmd/blcmdl8_lvcreate.htm" target="_blank" rel="external">–lvcreate</a></li>
<li>Configure the raid 0<ul>
<li>Login in the url: <a href="http://manage.windowsazure.com" target="_blank" rel="external">http://manage.windowsazure.com</a></li>
<li>Attached/Added 4 empty disks</li>
</ul>
</li>
<li>Create logical volume ( striped disks)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install lvm2</span><br><span class="line">// find the disk, using dmesg | grep SCSI</span><br><span class="line"><span class="comment">#  grep SCSI /var/log/dmesg</span></span><br><span class="line">$ sudo fdisk /dev/sdc  -&gt; n,p,1, enter, enter, p, w</span><br><span class="line">$ sudo fdisk /dev/sdd  -&gt; n,p,1, enter, enter, p, w</span><br><span class="line">$ sudo fdisk /dev/sde  -&gt; n,p,1, enter, enter, p, w</span><br><span class="line">$ sudo fdisk /dev/sdf  -&gt; n,p,1, enter, enter, p, w</span><br><span class="line">$ sudo pvcreate /dev/sdc1</span><br><span class="line">$ sudo pvcreate /dev/sdd1</span><br><span class="line">$ sudo pvcreate /dev/sde1</span><br><span class="line">$ sudo pvcreate /dev/sdf1</span><br><span class="line">//  sudo pvscan</span><br><span class="line">// merge all the drives together</span><br><span class="line">$ sudo vgcreate datadrive /dev/sdc1 /dev/sdd1 /dev/sde1 /dev/sdf1</span><br><span class="line">// sudo vgdisplay</span><br><span class="line">$ sudo lvcreate <span class="_">-l</span> 100%FREE datadrive -n example-log -I 64 -i 4</span><br><span class="line">// sudo lvdisplay</span><br><span class="line">//  sudo lvcreate -i &lt;number of physical volumes to stripe&gt; -I (大写i)&lt;size of stripe <span class="keyword">in</span> killobytes&gt; -L &lt;size <span class="keyword">in</span> megabytes&gt;M &lt;name of virtual group&gt;</span><br><span class="line">$ sudo mkfs -t ext4 /dev/datadrive/example-log</span><br><span class="line">$ sudo mkdir /datasource</span><br><span class="line">$ sudo mount /dev/datadrive/example-log /datasource</span><br></pre></td></tr></table></figure>
<ul>
<li>Automatic Mount configure (<a href="https://wiki.archlinux.org/index.php/Fstab" target="_blank" rel="external">fstab</a>)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo blkid</span><br><span class="line">sudo vim /etc/fstab</span><br><span class="line">/dev/mapper/datadrive-example--datalog: UUID=<span class="string">"b2e83db3-41b9-4f78-8b1f-f196bb9b9b6f"</span> TYPE=<span class="string">"ext4"</span></span><br><span class="line"></span><br><span class="line">UUID=b2e83db3-41b9-4f78-8b1f<span class="_">-f</span>196bb9b9b6f /datadrive ext4 defaults 0 0</span><br><span class="line">// An example from mine (bolded GUID is from my blkid, be sure to change it!): UUID=63ab0827-4698-427a-818a-279b18886757 /mnt/datadrive ext3 defaults 0 0</span><br><span class="line">// $ sudo chroot /target</span><br><span class="line">// Test disk write speed</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ time sh -c &quot;sudo dd if=/dev/zero of=/datasource/temp bs=4k count=2000000 &amp;&amp; sync&quot;</span><br></pre></td></tr></table></figure>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul>
<li>Login in <a href="http://manage.windowsazure.com" target="_blank" rel="external">http://manage.windowsazure.com</a>, build the server on Azure<ul>
<li>Set the host: example-hadoop.cloudapp.net</li>
<li>Create VM (Ubuntu 14 LTS), with 8 cores and 14GB RAM<ul>
<li>example-data01, example-data02, example-data03, example-data04</li>
</ul>
</li>
<li><a href="http://wiki.apache.org/hadoop/FAQ" target="_blank" rel="external">Hadoop FAQ</a></li>
</ul>
</li>
<li>ssh-keygen</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">admin@example-data01 $ <span class="built_in">cd</span> .ssh</span><br><span class="line">$ ssh-keygen -t rsa  -&gt; enter, enter, enter</span><br><span class="line">$ cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">// <span class="built_in">test</span> the key: $ ssh localhost  -&gt; successfully</span><br><span class="line">$ scp authorized_keys admin@example-data02:~/.ssh/</span><br><span class="line">$ scp authorized_keys admin@example-data03:~/.ssh/</span><br><span class="line">// <span class="built_in">test</span> $ ssh example-data02</span><br></pre></td></tr></table></figure>
<p>Download the Hadoop Binary on each node<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ Install java on ubuntu</span><br><span class="line">$ wget http://mirrors.cnnic.cn/apache/hadoop/common/stable/hadoop-2.7.1.tar.gz</span><br><span class="line">$ tar xvf hadoop-2.7.1.tar.gz</span><br><span class="line">$ mv hadoop-2.7.1 hadoop</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Construct the platform for Big Data project</p>
<h2 id="Build_HardDisk_RAID0"><a href="#Build_HardDisk_RAID0" class="headerlink" title="Build HardDisk RAID0"></a>Build HardDisk RAID0</h2><p>This paragraph describes the HDFS configure progress on Azure Cloud Server. You need have a azure account to login in and purchase the platform you will perform on. Here is my platform construction details to share with you.</p>]]>
    
    </summary>
    
      <category term="Hadoop" scheme="https://snakecy.github.io/tags/Hadoop/"/>
    
      <category term="Spark" scheme="https://snakecy.github.io/tags/Spark/"/>
    
      <category term="cloud-tech" scheme="https://snakecy.github.io/categories/cloud-tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[tools-summary]]></title>
    <link href="https://snakecy.github.io/2016/01/12/tools-summary/"/>
    <id>https://snakecy.github.io/2016/01/12/tools-summary/</id>
    <published>2016-01-11T18:48:57.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Summary the tools used in project, essential in big data direction </p>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><ul>
<li>Database: MySQL, NOSQL(redis), Hive, HBase</li>
<li>Platform: Windows8, Ubuntu, Debian</li>
<li>VM: VMware, Cywin, VirtualBox</li>
<li>Language: JAVA, R, Python, go, Ruby, Matlab</li>
<li>Shell: bash, perl</li>
<li>Bigdata Sys: SPARK, Hadoop, XAMPP</li>
<li>Algorithm: ML &amp; NL &amp; DM (DL)</li>
<li>Transfer: winSCP</li>
<li>Notes : WizNote , evernote</li>
<li>Office : OpenOffice, WPS</li>
<li>PHP, html5, <a href="https://nodejs.org/en/" target="_blank" rel="external">Node.js</a></li>
<li>Build evn: Maven, sbt</li>
<li>MLlib: liblinear-java, libsvm</li>
<li>SSH manager : putty manager, putty</li>
<li>Blog tools: WordPress, hexo</li>
<li>Redis <a href="https://redislabs.com/redis-java" target="_blank" rel="external">java</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>Summary the tools used in project, essential in big data direction </p>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools">]]>
    </summary>
    
      <category term="Software" scheme="https://snakecy.github.io/tags/Software/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Install Python GUI spyder on Mac]]></title>
    <link href="https://snakecy.github.io/2016/01/11/python-spyder/"/>
    <id>https://snakecy.github.io/2016/01/11/python-spyder/</id>
    <published>2016-01-10T16:22:08.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>The spyder tool of Python GUI works on Max OS</p>
<h2 id="Install_Python"><a href="#Install_Python" class="headerlink" title="Install Python"></a>Install Python</h2><h3 id="Install_Python_3-4-1_on_Ubuntu"><a href="#Install_Python_3-4-1_on_Ubuntu" class="headerlink" title="Install Python 3.4.1 on Ubuntu"></a>Install Python 3.4.1 on Ubuntu</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libssl-dev openssl</span><br><span class="line">wget https://www.python.org/ftp/python/3.4.1/Python-3.4.1.tgz</span><br><span class="line">tar -xvf Python-3.4.1.tgz</span><br><span class="line"><span class="built_in">cd</span> Python-3.4.1/</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line">&gt; <span class="keyword">then</span> run ./python <span class="keyword">in</span> terminal</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="Install_Python_3-4-1_on_Mac"><a href="#Install_Python_3-4-1_on_Mac" class="headerlink" title="Install Python 3.4.1 on Mac"></a>Install Python 3.4.1 on Mac</h3><p>Mac has installed the python 2.7, if you want to use the latest version,  go to the <a href="http://www.python.org/download/" target="_blank" rel="external">Python</a> website and download.</p>
<h2 id="Install_the_Python_GUI_on_Mac"><a href="#Install_the_Python_GUI_on_Mac" class="headerlink" title="Install the Python GUI on Mac"></a>Install the Python GUI on Mac</h2><h3 id="Step_1_2C_Intall_the_Python"><a href="#Step_1_2C_Intall_the_Python" class="headerlink" title="Step 1, Intall the Python"></a>Step 1, Intall the Python</h3><h3 id="Step_2_2C_Install_the_Anaconda"><a href="#Step_2_2C_Install_the_Anaconda" class="headerlink" title="Step 2, Install the Anaconda"></a>Step 2, Install the <a href="http://www.continuum.io/downloads" target="_blank" rel="external">Anaconda</a></h3><ul>
<li>Command-Line Install</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda2-2.4.1-MacOSX-x86_64.sh</span><br></pre></td></tr></table></figure>
<h3 id="Step_3_2C_Install_MacPorts"><a href="#Step_3_2C_Install_MacPorts" class="headerlink" title="Step 3, Install MacPorts"></a>Step 3, Install <a href="http://guide.macports.org/" target="_blank" rel="external">MacPorts</a></h3><p>Make sure that you have installed the XCode on mac, which is the encession to install “spyder”<br>Also for the MacPorts install <a href="http://www.ccvita.com/434.html" target="_blank" rel="external">reference</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -O https://distfiles.macports.org/MacPorts/MacPorts-2.3.3.tar.bz2</span><br><span class="line">tar xf MacPorts-2.3.3.tar.bz2</span><br></pre></td></tr></table></figure>
<p>Then, edit the /etc/profile file, add the following comand</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/opt/<span class="built_in">local</span>/bin:/opt/<span class="built_in">local</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p>For the first time to run:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo port -v selfupdate</span><br></pre></td></tr></table></figure>
<p>And if you update failed, you can re-run it with debug output, likes:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo port <span class="_">-d</span> selfupdate</span><br></pre></td></tr></table></figure>
<h3 id="Step_4_2C_install_spyder"><a href="#Step_4_2C_install_spyder" class="headerlink" title="Step 4, install spyder"></a>Step 4, install spyder</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo port install python27 // <span class="keyword">if</span> python27 dose not installed, <span class="keyword">then</span> install it before activate</span><br><span class="line">$ sudo port select --set python python27  // <span class="built_in">set</span> the default python</span><br><span class="line">$ sudo port select --list python // available versions</span><br><span class="line">$ sudo port <span class="_">-f</span> activate python27</span><br><span class="line">$ sudo port install py-spyder</span><br></pre></td></tr></table></figure>
<p>﻿After long time waiting. Then, begin our python journey, run the spyder in the terminal</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ spyder</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<p>The spyder tool of Python GUI works on Max OS</p>
<h2 id="Install_Python"><a href="#Install_Python" class="headerlink" title="Install Python"></a>Install Python</h2><h3 id="Install_Python_3-4-1_on_Ubuntu"><a href="#Install_Python_3-4-1_on_Ubuntu" class="headerlink" title="Install Python 3.4.1 on Ubuntu"></a>Install Python 3.4.1 on Ubuntu</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libssl-dev openssl</span><br><span class="line">wget https://www.python.org/ftp/python/3.4.1/Python-3.4.1.tgz</span><br><span class="line">tar -xvf Python-3.4.1.tgz</span><br><span class="line"><span class="built_in">cd</span> Python-3.4.1/</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line">&gt; <span class="keyword">then</span> run ./python <span class="keyword">in</span> terminal</span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="Mac" scheme="https://snakecy.github.io/tags/Mac/"/>
    
      <category term="Python" scheme="https://snakecy.github.io/tags/Python/"/>
    
      <category term="Spyder" scheme="https://snakecy.github.io/tags/Spyder/"/>
    
      <category term="open-source" scheme="https://snakecy.github.io/categories/open-source/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Build Blog with Github & Hexo]]></title>
    <link href="https://snakecy.github.io/2016/01/09/github-hexo/"/>
    <id>https://snakecy.github.io/2016/01/09/github-hexo/</id>
    <published>2016-01-08T16:00:00.000Z</published>
    <updated>2016-03-10T13:12:58.000Z</updated>
    <content type="html"><![CDATA[<p>Beginning the blog journey of Hexo &amp; Gituhub</p>
<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<a id="more"></a>
<h2 id="Quick_Start"><a href="#Quick_Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create_a_new_post"><a href="#Create_a_new_post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server"><a href="#Run_server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files"><a href="#Generate_static_files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites"><a href="#Deploy_to_remote_sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
<h2 id="Create_a_domain_of_yourself_bolg_website"><a href="#Create_a_domain_of_yourself_bolg_website" class="headerlink" title="Create a domain of yourself bolg website"></a>Create a domain of yourself bolg website</h2><h3 id="Step_1"><a href="#Step_1" class="headerlink" title="Step 1"></a>Step 1</h3><p>Register on <a href="https://support.dnspod.cn/Kb/showarticle/tsid/42/" target="_blank" rel="external">Godaddy</a>,  If possible, also should to use CDN on <a href="https://www.dnspod.cn/" target="_blank" rel="external">DNSPod</a></p>
<h3 id="Step_2"><a href="#Step_2" class="headerlink" title="Step 2"></a>Step 2</h3><p>Create Personal Rep. on github, and name the Rep. is <snakecy.github.io>, add the README.md file to describe the Rep.</snakecy.github.io></p>
<h3 id="Step_3"><a href="#Step_3" class="headerlink" title="Step 3"></a>Step 3</h3><p>Using ping to get github pages ip  &lt; 103.245.222.133&gt;</p>
<h3 id="Step_4"><a href="#Step_4" class="headerlink" title="Step 4"></a>Step 4</h3><p>On Mac OS, the necessary thing is to download Xcode CommandLine Tools in AppStore, and then<br><!-- download Xcode and install, then xcode-select --install --><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo xcode-select -switch /Applications/Xcode.app/Contents/Developer</span><br></pre></td></tr></table></figure></p>
<h3 id="Step_5"><a href="#Step_5" class="headerlink" title="Step 5"></a>Step 5</h3><p>Install jekyll (optional)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo gem update --system</span><br><span class="line">$ sudo gem install jekyll</span><br></pre></td></tr></table></figure></p>
<p>Install Hexo (use)</p>
<ul>
<li>Install Xcode and <a href="https://nodejs.org/en/" target="_blank" rel="external">Node.js</a></li>
<li>Install Hexo on mac</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo npm install hexo-cli -g</span><br><span class="line">$ mkdir blog</span><br><span class="line">$ <span class="built_in">cd</span> blog</span><br><span class="line">$ hexo init &amp; npm install</span><br></pre></td></tr></table></figure>
<p>Configure the homepage by</p>
<ul>
<li><a href="http://www.jianshu.com/p/73779eacb494" target="_blank" rel="external">jianshu</a></li>
<li><a href="http://theme-next.iissnan.com" target="_blank" rel="external">iissnan</a></li>
</ul>
<h2 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h2><h3 id="Update_hexo"><a href="#Update_hexo" class="headerlink" title="Update hexo"></a>Update hexo</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm update -g hexo</span><br></pre></td></tr></table></figure>
<h3 id="Update_themes"><a href="#Update_themes" class="headerlink" title="Update themes"></a>Update themes</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> themes/next</span><br><span class="line">$ git pull</span><br></pre></td></tr></table></figure>
<h3 id="Update_plugins"><a href="#Update_plugins" class="headerlink" title="Update plugins"></a>Update plugins</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ npm update</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">### Add plugins</span></span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">npm install hexo-generator-index --save</span><br><span class="line">npm install hexo-generator-archive --save</span><br><span class="line">npm install hexo-generator-category --save</span><br><span class="line">npm install hexo-generator-tag --save</span><br><span class="line">npm install hexo-server --save</span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">npm install hexo-deployer-heroku --save</span><br><span class="line">npm install hexo-deployer-rsync --save</span><br><span class="line">npm install hexo-deployer-openshift --save</span><br><span class="line">npm install hexo-renderer-marked@0.2.7 --save</span><br><span class="line">npm install hexo-renderer-stylus@0.3.0 --save</span><br><span class="line">npm install hexo-generator-feed@1.0.3 --save</span><br><span class="line">npm install hexo-generator-sitemap@1.0.1 --save</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<p>Beginning the blog journey of Hexo &amp; Gituhub</p>
<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>]]>
    
    </summary>
    
      <category term="Hexo + Github" scheme="https://snakecy.github.io/tags/Hexo-Github/"/>
    
      <category term="Mac" scheme="https://snakecy.github.io/tags/Mac/"/>
    
      <category term="web-building" scheme="https://snakecy.github.io/categories/web-building/"/>
    
  </entry>
  
</feed>
